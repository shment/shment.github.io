{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Walmart Dataset Solution - MLP","metadata":{}},{"cell_type":"markdown","source":"This notebook and others can be downloaded from [here](https://github.com/shment/shment.github.io).","metadata":{}},{"cell_type":"markdown","source":"Walmart [dataset](https://www.kaggle.com/datasets/yasserh/walmart-dataset) consist of the weekly sales in different Walmart stores from 2010-02-05 to 2012-11-01. Our goal here is to predict the sales for a given week.\nIn this notebook we will see how to:\n1. load data stored in a csv file to pandas dataframe\n2. convert categorical to numeric features using scikit learn\n3. handle date feature \n4. scale numeric features to be suitable for MLP\n5. learn MLP model using pytorch to predict the sales\n6. save and load the model and other auxiliaries for inference on new samples ","metadata":{}},{"cell_type":"markdown","source":"First we will import the libraries we will use:","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch \nimport torch.nn as nn\nimport torch.utils.data as data\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-31T14:37:28.004198Z","iopub.execute_input":"2023-01-31T14:37:28.004788Z","iopub.status.idle":"2023-01-31T14:37:28.014406Z","shell.execute_reply.started":"2023-01-31T14:37:28.004745Z","shell.execute_reply":"2023-01-31T14:37:28.012980Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"Next we load the data to pandas dataframe and separate the target variable(weekly sales) from the rest.","metadata":{}},{"cell_type":"code","source":"df_x = pd.read_csv('/kaggle/input/walmart-dataset/Walmart.csv')\ndf_y = df_x['Weekly_Sales']\ndf_x = df_x.drop(columns=['Weekly_Sales'])","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:37:28.023398Z","iopub.execute_input":"2023-01-31T14:37:28.023816Z","iopub.status.idle":"2023-01-31T14:37:28.050054Z","shell.execute_reply.started":"2023-01-31T14:37:28.023775Z","shell.execute_reply":"2023-01-31T14:37:28.049010Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"Here we check for problems in the data such as nan values and wrong data type.","metadata":{}},{"cell_type":"code","source":"pd.concat([df_x.nunique(axis=0), df_x.isna().sum(axis=0), df_x.dtypes], axis=1).rename(columns={0: 'uniques', 1:'na', 2:'type'})","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:37:28.055284Z","iopub.execute_input":"2023-01-31T14:37:28.058444Z","iopub.status.idle":"2023-01-31T14:37:28.089102Z","shell.execute_reply.started":"2023-01-31T14:37:28.058400Z","shell.execute_reply":"2023-01-31T14:37:28.087674Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"              uniques  na     type\nStore              45   0    int64\nDate              143   0   object\nHoliday_Flag        2   0    int64\nTemperature      3528   0  float64\nFuel_Price        892   0  float64\nCPI              2145   0  float64\nUnemployment      349   0  float64","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uniques</th>\n      <th>na</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Store</th>\n      <td>45</td>\n      <td>0</td>\n      <td>int64</td>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <td>143</td>\n      <td>0</td>\n      <td>object</td>\n    </tr>\n    <tr>\n      <th>Holiday_Flag</th>\n      <td>2</td>\n      <td>0</td>\n      <td>int64</td>\n    </tr>\n    <tr>\n      <th>Temperature</th>\n      <td>3528</td>\n      <td>0</td>\n      <td>float64</td>\n    </tr>\n    <tr>\n      <th>Fuel_Price</th>\n      <td>892</td>\n      <td>0</td>\n      <td>float64</td>\n    </tr>\n    <tr>\n      <th>CPI</th>\n      <td>2145</td>\n      <td>0</td>\n      <td>float64</td>\n    </tr>\n    <tr>\n      <th>Unemployment</th>\n      <td>349</td>\n      <td>0</td>\n      <td>float64</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"The data don't have nan values, but the *Store* and *Holiday_Flag* features need to be categorical - there is no sense in \"store 1 is bigger then store 0\". In addition, the *Date* feature has order - 2010-02-05 is before 2010-02-06, so we need to convert it to numerical feature in a way that will that into account. In addition, the month and the year has valuable information that we want to keep (November sales are probably higher). Simple way for doing that is to create 3 new features - *day*, *month* and *year*. If we needed to predict daily sales, since there is likely a correlation between the week day and the sales, we should have added another feature for the weekday (Sunday, Monday,...). However, since we are predicting weekly sales, it has no meaning for our problem.","metadata":{}},{"cell_type":"code","source":"df_x['Store'] = df_x['Store'].astype(object)\ndf_x['Holiday_Flag'] = df_x['Holiday_Flag'].astype(object)\n\ndf_x['Date'] = pd.to_datetime(df_x['Date'])\ndf_x['day'] = df_x['Date'].dt.day\ndf_x['month'] = df_x['Date'].dt.month\ndf_x['year'] = df_x['Date'].dt.year\n\ndf_x = df_x.drop(columns=['Date'])","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:37:28.090734Z","iopub.execute_input":"2023-01-31T14:37:28.091451Z","iopub.status.idle":"2023-01-31T14:37:28.112597Z","shell.execute_reply.started":"2023-01-31T14:37:28.091411Z","shell.execute_reply":"2023-01-31T14:37:28.111546Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"Split the data to train and test sets.\n","metadata":{}},{"cell_type":"code","source":"#train test split\nx_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.1, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:37:28.114993Z","iopub.execute_input":"2023-01-31T14:37:28.115624Z","iopub.status.idle":"2023-01-31T14:37:28.125993Z","shell.execute_reply.started":"2023-01-31T14:37:28.115585Z","shell.execute_reply":"2023-01-31T14:37:28.124767Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"MLP requires all features to be in the same scale. Here we scale them to have mean=0 and std=1.","metadata":{}},{"cell_type":"code","source":"numeric_features = list(x_train.loc[:, x_train.dtypes != object])\nnumeric_encoder = StandardScaler()\nnumeric_encoder.fit(x_train.loc[:, numeric_features])\nx_train.loc[:, numeric_features] = numeric_encoder.transform(x_train.loc[:, numeric_features])\nx_test.loc[:, numeric_features] = numeric_encoder.transform(x_test.loc[:, numeric_features])","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:37:28.127634Z","iopub.execute_input":"2023-01-31T14:37:28.128290Z","iopub.status.idle":"2023-01-31T14:37:28.178531Z","shell.execute_reply.started":"2023-01-31T14:37:28.128252Z","shell.execute_reply":"2023-01-31T14:37:28.177368Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"In order to convert the categorical features to numeric ones, we use one hot encoding.","metadata":{}},{"cell_type":"code","source":"categorical_features = list(x_train.loc[:, x_train.dtypes == object])\ncat_encoder = OneHotEncoder()\ncat_encoder.fit(x_train.loc[:, categorical_features])\n\ntransformed = cat_encoder.transform(x_train.loc[:, categorical_features].to_numpy())\nohe = pd.DataFrame(transformed.toarray(), columns=cat_encoder.get_feature_names_out())\nx_train = x_train.reset_index()\nx_train = pd.concat([x_train, ohe], axis=1)\nx_train = x_train.drop(columns=categorical_features)\n\ntransformed = cat_encoder.transform(x_test.loc[:, categorical_features].to_numpy())\nohe = pd.DataFrame(transformed.toarray(), columns=cat_encoder.get_feature_names_out())\nx_test = x_test.reset_index()\nx_test = pd.concat([x_test, ohe], axis=1)\nx_test = x_test.drop(columns=categorical_features)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:37:28.180157Z","iopub.execute_input":"2023-01-31T14:37:28.180749Z","iopub.status.idle":"2023-01-31T14:37:28.214481Z","shell.execute_reply.started":"2023-01-31T14:37:28.180712Z","shell.execute_reply":"2023-01-31T14:37:28.213460Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n  \"X does not have valid feature names, but\"\n/opt/conda/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n  \"X does not have valid feature names, but\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Next we define our model. Input for the model is a list of the dimensions.","metadata":{}},{"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self, dims):\n        super().__init__()\n        self.dims = dims\n        self.layers = nn.ModuleList()\n        for i in range(len(dims) - 1):\n            self.layers.append(nn.Linear(dims[i], dims[i + 1]))\n\n        self.activation = nn.ReLU()\n\n    def forward(self, x):\n        for i, layer in enumerate(self.layers):\n            x = layer(x)\n            if i < len(self.layers) - 1:\n                x = self.activation(x)\n        \n        if self.dims[-1] == 1:\n            return x.view(-1)\n        else:\n            return x","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:37:28.216276Z","iopub.execute_input":"2023-01-31T14:37:28.217040Z","iopub.status.idle":"2023-01-31T14:37:28.227085Z","shell.execute_reply.started":"2023-01-31T14:37:28.216997Z","shell.execute_reply":"2023-01-31T14:37:28.225591Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"and the dataset","metadata":{}},{"cell_type":"code","source":"class MyDataset(data.Dataset):\n    def __init__(self, x, y):\n        super().__init__()\n        self.x = x.to_numpy()\n        self.y = y.to_numpy()\n\n    def __getitem__(self, index):\n        sample = self.x[index]\n        target = self.y[index]\n        return torch.from_numpy(sample).float(), torch.from_numpy(np.array(target)).float()\n\n    def __len__(self):\n        return self.y.shape[0]","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:37:28.231572Z","iopub.execute_input":"2023-01-31T14:37:28.232502Z","iopub.status.idle":"2023-01-31T14:37:28.242646Z","shell.execute_reply.started":"2023-01-31T14:37:28.232462Z","shell.execute_reply":"2023-01-31T14:37:28.240595Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"Choose hyperparameters","metadata":{}},{"cell_type":"code","source":"loss_func = nn.L1Loss()\nbatch_size = 512\nlearning_rate = 0.01\nnum_epochs = 2000\ndims = [55, 512, 512, 1]\ndecay_every = 500\ndecay = 0.5\nmodel_dims = {'dims': dims}","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:37:28.245249Z","iopub.execute_input":"2023-01-31T14:37:28.248038Z","iopub.status.idle":"2023-01-31T14:37:28.254741Z","shell.execute_reply.started":"2023-01-31T14:37:28.247997Z","shell.execute_reply":"2023-01-31T14:37:28.252992Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"Now we can set every thing up:\n1. create a model and move it to gpu\n2. create an optimizer - we use learning rate decay here\n3. create dataloader","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nmodel = MLP(dims)\nmodel = model.to(device)\nprint(model)\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\nscheduler = StepLR(optimizer, decay_every, gamma=decay)\ntrain_dataset = MyDataset(x_train, y_train)\ntest_dataset = MyDataset(x_test, y_test)\ntrain_loader = data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:37:28.257580Z","iopub.execute_input":"2023-01-31T14:37:28.259687Z","iopub.status.idle":"2023-01-31T14:37:28.282406Z","shell.execute_reply.started":"2023-01-31T14:37:28.259642Z","shell.execute_reply":"2023-01-31T14:37:28.279545Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"MLP(\n  (layers): ModuleList(\n    (0): Linear(in_features=55, out_features=512, bias=True)\n    (1): Linear(in_features=512, out_features=512, bias=True)\n    (2): Linear(in_features=512, out_features=1, bias=True)\n  )\n  (activation): ReLU()\n)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"and start the training loop.","metadata":{}},{"cell_type":"code","source":"for epoch in range(1, num_epochs + 1):\n    print('epoch:', epoch)\n    model.train()\n    for samples, targets in train_loader:\n        samples = samples.to(device)\n        targets = targets.to(device)\n        preds = model(samples)\n        loss = loss_func(preds, targets)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step() \n        \n    scheduler.step()\n    model.eval() \n    with torch.no_grad():\n        for mode, loader in zip(['train', 'test'], [train_loader, test_loader]):\n            epoch_loss, rel_abs_error, num_samples = 0, 0, 0\n            for samples, targets in loader:\n                samples = samples.to(device)\n                targets = targets.to(device)\n                preds = model(samples)\n                loss = loss_func(preds, targets)\n                epoch_loss += loss.item() * targets.shape[0] \n                rel_abs_error += torch.abs((targets - preds) / targets).sum() \n                num_samples += targets.shape[0]\n\n            epoch_loss = epoch_loss / num_samples\n            rel_abs_error = rel_abs_error / num_samples\n            print(mode, '- mae:', f'{epoch_loss:.2}', 'mape:', f'{rel_abs_error:.2}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model is ready, we can save it and the one hot encoder for future use.\n","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), 'model.ckpt')\njoblib.dump(model_dims, 'model_dims.joblib')\njoblib.dump(numeric_encoder, 'numeric_encoder.joblib')\njoblib.dump(cat_encoder, 'cat_encoder.joblib')\njoblib.dump(numeric_features, 'numeric_features.joblib')\njoblib.dump(categorical_features, 'categorical_features.joblib')","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:43:45.000243Z","iopub.execute_input":"2023-01-31T14:43:45.001312Z","iopub.status.idle":"2023-01-31T14:43:45.019741Z","shell.execute_reply.started":"2023-01-31T14:43:45.001272Z","shell.execute_reply":"2023-01-31T14:43:45.018770Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"['categorical_features.joblib']"},"metadata":{}}]},{"cell_type":"markdown","source":"Here is how to use the model on new data.\nNumerical and categorical encoding already done on *x_test* so we skip this part","metadata":{}},{"cell_type":"code","source":"model_dims = joblib.load('model_dims.joblib')\nmodel = MLP(model_dims['dims'])\nmodel.load_state_dict(torch.load('model.ckpt'))\nnumeric_encoder = joblib.load('numeric_encoder.joblib')\ncat_encoder = joblib.load('cat_encoder.joblib')\nnumeric_features = joblib.load('numeric_features.joblib')\ncategorical_features = joblib.load('categorical_features.joblib')\n\n_, df_inference, _, _ = train_test_split(df_x, df_y, test_size=0.1, random_state=1)\n\n'''\nx_test.loc[:, numeric_features] = numeric_encoder.transform(x_test.loc[:, numeric_features])\ntransformed = cat_encoder.transform(x_test.loc[:, categorical_features].to_numpy())\nohe = pd.DataFrame(transformed.toarray(), columns=cat_encoder.get_feature_names_out())\nx_test = x_test.reset_index()\nx_test = pd.concat([x_test, ohe], axis=1)\nx_test = x_test.drop(columns=categorical_features)\n'''","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:43:45.021755Z","iopub.execute_input":"2023-01-31T14:43:45.022755Z","iopub.status.idle":"2023-01-31T14:43:45.044680Z","shell.execute_reply.started":"2023-01-31T14:43:45.022718Z","shell.execute_reply":"2023-01-31T14:43:45.043914Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"'\\nx_test.loc[:, numeric_features] = numeric_encoder.transform(x_test.loc[:, numeric_features])\\ntransformed = cat_encoder.transform(x_test.loc[:, categorical_features].to_numpy())\\nohe = pd.DataFrame(transformed.toarray(), columns=cat_encoder.get_feature_names_out())\\nx_test = x_test.reset_index()\\nx_test = pd.concat([x_test, ohe], axis=1)\\nx_test = x_test.drop(columns=categorical_features)\\n'"},"metadata":{}}]},{"cell_type":"markdown","source":"Now we can use our model to predict weekly sales of the new data. \nWe need to move the model and data to the same device, and performe the necessary manipulation as done in the dataloader.\nFor debuging, we can save our predictions in a csv file.","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\ntest_pred = model(torch.from_numpy(x_test.to_numpy()).float().to(device))\ntest_pred = test_pred.detach().cpu().numpy()\nmae = mean_absolute_error(test_pred, y_test)\nmape = mean_absolute_percentage_error(test_pred, y_test)\nprint('MAE:', mae)\nprint('MAPE:', mape)\ndf_inference['pred'] = test_pred\ndf_inference['mae'] = np.abs(test_pred - y_test)\ndf_inference['mape'] = mae / y_test\ndf_inference.to_csv('df_inference.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:43:45.047605Z","iopub.execute_input":"2023-01-31T14:43:45.048586Z","iopub.status.idle":"2023-01-31T14:43:45.071445Z","shell.execute_reply.started":"2023-01-31T14:43:45.048542Z","shell.execute_reply":"2023-01-31T14:43:45.070302Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"MAE: 70074.20480007764\nMAPE: 0.06552580466433054\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The following figure shows that prediction of weekly sales for some stores are harder.","metadata":{}},{"cell_type":"code","source":"df_groupby_store = df_inference.groupby(['Store']).mean()\nfig, ax = plt.subplots()\nax.bar(df_groupby_store.index, df_groupby_store['mape'])\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-01-31T14:43:45.072895Z","iopub.execute_input":"2023-01-31T14:43:45.073599Z","iopub.status.idle":"2023-01-31T14:43:45.370036Z","shell.execute_reply.started":"2023-01-31T14:43:45.073558Z","shell.execute_reply":"2023-01-31T14:43:45.368984Z"},"trusted":true},"execution_count":67,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}